---
title: linux故障解决
date: 2017-09-30 11:49:45
tags:
    -linux故障
categories:
    -linux
---
问题1：Read-only file system 错误与解决方法
-------------------------------------------------------------------------
解析：出现这个问题的原因有很多种，可能是文件系统数据块出现不一致导致的，也可能是磁盘故障造成的，主流ext3/ext4文件系统都有很强的自我修复机制，对于简单的错误，文件系统一般都可以自行修复，当遇到致命错误无法修复的时候，文件系统为了保证数据一致性和安全，会暂时屏蔽文件系统的写操作，讲文件系统 变为只读,
今儿出现了上面的“read-only file system”现象。
手工修复文件系统错误的命令式fsck，在修复文件系统前，最好卸载文件系统所在的磁盘分区
```bash
umount /www/data
Umount : /www/data: device is busy
```
提示无法卸载，可能是这个磁盘中还有文件对应的进程在运行，检查如下：
```bash 
fuser –m /dev/sdb1
/dev/sdb1: 8800
```
接着检查一下8800端口对应的什么进程，
```bash
 ps –ef |grep 8800
```
检查后发现时apache没有关闭，停止apache
```bash
/usr/local/apache2/bin/apachectl stop
umount /www/data
fsck –V –a /dev/sdb1
mount /dev/sdb1 /www/data
```

问题2：“Argument list too long”错误与解决方法
---------------------------------------------------------------------
```bash
crontab –e
```
编辑完后保存退出后，报错no space left on device
根据上面的报错了解到是磁盘空间满了，那么首先是检查磁盘空间，
```bash
df –h
```
查看到是/var磁盘分区空间已经达到100%，至此定位了问题所在。是/var磁盘空间饱满导致，因为crontab会在保存时将文件信息写到/var目录下面，然而这个磁盘没有空间了，所以报错。
接着通过命令du –sh * 命令检查/var目录下面的所有文件或者目录的大小，发现/var/spool/clientmqueue目录占用了/var整个分区大小的90%，那么/var/spool/clientmqueue目录下的文件都是怎么产生的，能否删除，基本上都是邮件信息，可以删除
```bash 
rm *
/bin/rm :argument list too long
```
当在linux 系统中试图传递太多参数给一个命令时，就会出现“argument list too long ”错误，这是linux系统一直以来都有的限制，查看这个限制可以通过命令“getconf ARG_MAX”来实现，
```bash
getconf ARG_MAX
more /etc/issue 查看版本
```
解决方法：1、
```bash
rm [a-n]* -rf
rm [o-z]* -rf
```
2、使用find命令来删除
```bash
find /var/spool/clientmqueue –type f –print –exec rm –f {} \;
```
3、通过shell脚本
```bash
#/bin/bash
RM_DIR=’/var/spool/clientmqueue’
cd $RM_DIR
for I in `ls`
do
rm –f $i
done
```
4、重新编译内核
需要手动增加内核中分配给命令行参数的页数，打开kernel source 下面的include/linux/binfmts.h文件，找到如下行：
```bash
denfine MAX_ARG_PAGES 32
将32改为更大的值，例如64或者128，然后重新编译内核
```
问题3：inode耗尽导致应用故障
--------------------------------------------------------------------------------
客户的一台Oracle数据库如武器在关机重启后，Oracle监听无法启动，提示报错 Linux error : No space left on device
从输出信息看出来是因为磁盘耗尽导致监听无法启动，因为Oracle在启动监听时需要创建监听日志文件，于是首先查看磁盘空间使用情况
```bash 
df –h
```
从磁盘输出信息可知，所有的分区磁盘空间都还有剩余不少，而Oracle监听写日志的路径在/var分区下，/var下分区空间足够。
解决思路：
既然错误提示语磁盘空间有关，那就深入研究关于磁盘空间的问题，
在linux系统中对磁盘空间的占用分为三个部分：
第一个是物理磁盘空间，
第二个是inode节点所占用的磁盘空间，
第三个是linux用来存放信号量的空间

而平时接触较多的是物理磁盘空间。既然不是物理磁盘空间的问题，接着就检查是否是inode节点耗尽的问题，通过执行命令“df -i”查看可用的inode节点。由输出结果看出确实是因为inode耗尽导致无法写入文件。
可以通过下面的命令查看某个磁盘分区inode的总数
```bash
dumpe2fs –h /dev/sda3 |grep ‘Inode count’
```
每个inode都有一个号码，操作系统用inode号码来区分不同的文件，通过‘ls -i’命令可以查看文件名对应的inode号
如果要查看这个文件更详细的inode信息，可以通过stat命令来实现
```bash
stat install.log
```
解决问题
```bash
find /var/spool/clientmqueue/ -name “*” –exec rm –rf {} \;
```
问题4：文件已经删除，但是空间没有释放的原因
------------------------------------------------------------------------------
运维监控系统发来通知，报告一台服务器空间满了;
登陆服务器查看，根分区确实满了;
这里先说一下服务器的一些删除策略，由于linux没有回收站功能，所以线上服务器上所有要删除的文件都会先移到系统/tmp目录下，然后定期清除/tmp目录下的数据。
这个策略本身没有什么问题，但是通过检查发现这台服务器的系统分区中并没有单独划分/tmp分区，这样/tmp下的数据其实占用根分区的空间，既然找到了问题，那么删除/tmp目录下一些占用空间较大的数据文件即可。
```bash
du –sh /tmp/* | sort –nr |head -3
```
通过命令发现在/tmp目录下有个66G大小的文件access_log，这个文件应该是apache产生的访问日志文件，从日志大小来看，应该是很久没有清理的apache日志文件了，基本判定是这个文件导致的根空间爆满，在确认此文件可以删除后，执行如下删除命令，
```bash
rm /tmp/access_Iog
df –h
```
从输出来看，根分区空间仍然没有释放，这是怎么回事
一般来说不会出现删除文件后空间不释放的情况，但是也存在例外，比如文件进程锁定，或者有进程一直在向这个文件写数据，要理解这个问题，就需要知道linux下文件的存储机制和存储结构。
一个文件在文件系统中存放分为两个部分：数据部分和指针部分，指针位于文件系统的meta-data中，在将数据删除后，这个指针就从meta-data中清除了，而数据部分存储在磁盘中。在将数据对应的指针从meta-data中清除后，文件数据部分占用的空间就可以被覆盖并写入新的内容，之所以出现删除access_log文件后，空间还没有释放，就是因为httpd进程还在一直向这个文件写入内容，导致虽然删除了access_Ilog文件，但是由于进程锁定，文件对应的指针部分并未从meta-data中清除，而由于指针并未删除，系统内核就认为文件并未被删除，因此通过df命令查询空间并未释放。
问题排查：
既然有了解决思路，那么接下来看看是否有进程一直在向access_log文件中写入数据，这里需要用到linux下的losf命令，通过这个命令可以获取一个仍然被应用程序占用的已删除文件列表
```bash
lsof |grep delete
```
从输出可以看出，/tmp/access_log文件被进程httpd锁定，而httpd进程还一直向这个文件写入日志数据，最后一列的‘deleted’状态说明这个日志文件已经被删除，但是由于进程还在一直向此文件写入数据，因此空间并未释放。
解决问题：
到这里问题就基本排查清楚了，解决这一类问题的方法有很多，最简单的方法就是关闭或者重启httpd进程，当然重启操作系统也可以。不过这些并不是最好的办法，对待这种进程不停对文件写日志的操作，要释放文件占用的磁盘空间，最好的方法是在线清空这个文件，具体可以通过如下命令完成:
```bash
echo “ ” >/tmp/access_log
```
通过这种方法，磁盘空间不但可以马上释放，也可以保障进城继续向文件写入日志，这种方法经常用于在线清理apache /tomcat/nginx等web服务产生的日志文件。

问题5：“too many open files”错误与解决方法
------------------------------------------------------------------------------
问题现象：这是一个基于java的web应用系统，在后台添加数据时提示无法添加，于是登陆服务器查看tomcat日志，发现如下异常信息，java.io.IOException: Too many open files
通过这个报错信息，基本判断是系统可以用的文件描述符不够了，由于tomcat服务室系统www用户启动的，于是以www用户登陆系统，通过ulimit –n 命令查看系统可以打开最大文件描述符的数量，输出如下：
```bash
$ ulimit –n
65535
```
可以看到这台服务器设置的最大可以打开的文件描述符已经是65535了，这么大的值应该够用了，但是为什么提示这样的错误呢
解决思路，这个案例涉及ulimit命令的使用
在使用ulimit时，有以下几种使用方法：
1、 在用户环境变量中加入
如果用户使用的是bash，那么可以在用户目录的环境变量文件.bashrc或者.bash_profile中加入“ulimit –u128”来限制用户最多可以使用128个进程

2、 在应用程序的启动脚本中加入
如果应用程序是tomcat，那么可以再tomcat的启动脚本startup.sh中加入‘ulimit –n 65535’来限制用户最多可以使用65535个文件描述符

3、 直接在shell命令终端执行ulimit命令
这种方法的资源限制仅仅在执行命令的终端生效，在退出或者和关闭终端后，设置失效，并且这个设置不影响其他shell终端

解决问题：

在了解ulimit知识后，接着上面的案例，既然ulimit设置没有问题，那么一定是设置没有生效导致的，接下来检查下启动tomcat的www用户环境变量是否添加ulimit限制，检查后发现，www用户并无ulimit限制。于是继续检查tomcat启动脚本startup.sh文件是否添加了ulimit限制，检查后发现也没有添加。最后考略是否将限制加到了limits.conf文件中，于是检查limits.conf文件，操作如下
```bash
$ cat /etc/security/limits.conf |grep www
www soft nofile 65535
www hard nofile 65535
```
从输出可知，ulimit限制加在limits.conf文件中，既然限制已经添加了，配置也没有什么错，为何还会报错，经过思考，判断只有一种可能，那就是tomcat的启动时间早于ulimit资源限制的添加时间，于是首先查看下tomcat启动时间，操作如下
```bash
# uptime
Up 283 days
# pgrep –f tomcat
4667
# ps –eo pid,lstart,etime|grep 4667
4667 Sat Jul 6 09;33:39 2013 77-05:26:02
```
从输出可以看出，这台服务器已经有283没有重启了，而tomcat是在2013年7月6日9点启动的，启动了将近77天，接着继续看看limits.conf文件的修改时间，
```bash
$ stat /etc/security/limits.conf
```
通过stat命令清除的看到，limits.conf文件最后的修改时间是2013年7月12，晚于tomcat启动时间，清楚问题后，解决问题的方法很简单，重启一下tomcat就可以了。

问题6：（Apache常见错误故障案例）”no space left on device “错误与解决方法
--------------------------------------------------------------------

错误现象： 客户反映在执行”apachectl start “启动Apache是无报错信息，但是还是不能访问网页，客户的网站是基于Apache+PHP+mysql 的在线交易平台，听到客户描述的现象后，第一反应就是防火墙屏蔽了HTTP端口或selinux的问题，于是登陆服务器查看相关信息，从输出信息可以看出，防火墙所有的策略都处于开放状态，并未做出任何限制，而selinux也处于关闭状态，应该不是防火墙导致的。既然不是防火墙导致的，那么看看httpd进程是否存在及httpd端口是否正常启动
```bash
$ ps –ef |grep httpd|grep –v “grep” |wc –l
0
$ netstat –nultp |grep 80
$ /usr/local/apache2/bin/apachectl start
$ ps –ef |grpe httpd |grep –v “grep” |wc –l
0
```
这个操作首先查看了服务器上的httpd进程，发现并没有HTTP进程运行，同时httpd对应的端口80也并没有启动，于是重启Apache，在启动Apache的过程中并没有报错，启动完成后发现仍然HTTP进程没有运行，由此看来，应该是Apache内部出现了问题

解决思路：

在判断Apache问题后，首先要看的就是Apache的启动日志，在查看Apache的error日志后，发现了一个可疑输出，内容为：
```bash
#No space left on device : mod_rewrite: could not create rewrite_log_lock configuration failed
```
看到这个错误提示，感觉应该是磁盘空间耗尽导致，于是赶紧查看系统系统所有磁盘分区，结果发现所有磁盘分区都还有很多可用空间;
这就奇怪了，在前面的案例介绍中，详细介绍了linux对磁盘空间的占用分为三个部分:物理磁盘、inode节点磁盘空间和信号量磁盘空间。
通过检查服务器的物理磁盘空间，发现仍有很多剩余，因此排除物理空间的问题，接着通过”df -i”命令查看系统可用的inode节点，发现每个分区可以用的inode还有很多，这样inode节点问题也被排除了，那么应该是信号量磁盘空间耗尽导致的。

这里简单的介绍下linux信号量相关知识。信号量是一种锁机制，用于协调进程之间互斥的访问临界资源，以确保某种共享资源不被多个进程同时访问。
Linux系统的信号量是用于进程间通信的。它有两种标准实现，分别是POSIX及System v ，现在大多数linux系统都实现了这两种标准，这两种标准都可用于进行线程间的通信，只是系统调用方式略有不同。
System v 信号量通过系统调用semget来创建，通过linux命令ipcs即可显示进程间通信用的system v 类型信号量及共享内存。
Posix 信号量可用于线程和进程间通信，并可分为有名和无名两种，也可以理解为是否保存在磁盘上。
解决问题：
```bash
$ cat /proc/sys/kernel/sem
$ ipcs –s |grep daemon
```
Daemon是启动Apache进程的用户，默认是daemon，也可能是nobody用户，根据实际环境而定。解决信号量耗尽的方法很简单，通过ipcrm命令清除即可，最简单方法是执行如下命令组合：
```bash
$ ipcs –s |grep nobody |perl –e ‘while (<STDIN>) { @a=split(/\s+/);print `ipcrmsem $a[1]` }’
```
问题7：linux系统无法启动的解决方法
--------------------------------------------------------------------------------
这是linux最常见的故障，系统在掉电，以及执行配置更新、软件升级、内核升级后都有可能导致系统无法启动，究其原因，可能有很多种，常见的如下几种：

1） 文件系统破坏，一般是linux的根分区文件系统遭到破坏，导致系统无法启动，这种情况一般是有系统突然掉电或者非法关机引起的。

2） 文件系统配置不当，比如/etc/inittab文件、/etc/fstab文件等配置错误或丢失，导致系统错误，无法启动，这种情况一般是执行配置更新时人为导致的

3） Linux内核文件丢失或者崩溃，从而导致系统无法引导启动，这种情况可能是内核升级错误或者内核存在bug引起的

4） 系统引导程序出现问题，比如grub丢失或者损坏，导致系统无法引导启动，这种情况一般是人为修改错误或者文件系统故障导致的。

5） 系统硬件故障，比如主板、电源、硬盘等出现问题，导致linux系统无法正常启动，这种情况基本都是由于服务器硬件问题导致的。

问题8：文件系统破坏导致系统无法启动
--------------------------------------------------------------------------------
```bash
Checking root filesystem
/dev/sda6 contains a file system with errors, check forced
An error occurred during the file system check
```
这个错误可以看出，操作系统/dev/sda6分区文件系统出现了问题，这个问题发生的机率很高，通常引起这个问题的原因主要是系统突然断电，引起文件系统结构不一致，一般情况下，解决此问题的方法是采用fsck命令，进行强制修复。
```bash
$ umount /dev/sda6
$ fsck.ext3 –y /dev/sda6
```
问题9：访问权限问题
--------------------------------------------------------------------------------
当某些服务不能访问的时候，一定要检查是否被linux本机防火墙iptables屏蔽了，可以通过iptables –L –n 命令检查iptables的配置策略。
```bash
$ iptables –L –n
$ iptables –A INPUT –i eth0 –p tcp --dport 80 –j ACCEPT
$ iptables –A OUTPUT –p tcp --sport 80 –m state –state ESTABLISHED –j ACCEPT
```
--------------------------------------------------------------------------------
